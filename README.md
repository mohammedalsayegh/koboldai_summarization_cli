# KoboldAI Summarization Tools

This repository contains a collection of Rust command-line utilities designed to streamline various text processing tasks using LLM with help of KoboldAI's API and other functionalities. Each utility serves a specific purpose and can be used independently or in conjunction with others to enhance text processing workflows.

## Main Project

### KoboldAI Summarization CLI
The `koboldai_summarization_cli` utility is the main project of this repository. It provides a convenient way to generate document summaries using KoboldAI's API. It allows users to summarize large text documents into concise summaries using parameters customizable via JSON. Key features include:
- Utilization of KoboldAI's language model for accurate and coherent summarization.
- Batch processing of text files.
- Customizable summarization parameters.
- Integration with workflows via a command-line interface.

## Utilities

The repository also includes several auxiliary utilities to complement the main project:

### 1. JSON Text Merger
The `json_text_merger` utility simplifies the merging of text entries from JSON files into a single text file. It parses structured JSON data, sorts text entries based on numeric values in filenames, and merges them into a cohesive text document. Main features include:
- Parsing and extraction of text entries from JSON files.
- Sorting based on numeric values in filenames.
- Merging of sorted text entries into a single text file.

### 2. HTML to Transcript Converter (noScribe Transcript Extractor)
The `noscribe_transcript_extractor` utility converts HTML files generated by noScribe into transcript text files. It extracts script text and corresponding start and end times from HTML files, facilitating easy conversion for further processing. Key features include:
- Conversion of HTML files to transcript text files.
- Extraction of script text and timestamps.
- Support for single file or batch conversion.

### 3. Transcript Splitter
The `transcript-splitter` utility divides transcript text files into smaller parts based on a specified maximum number of tokens per split. It aims to simplify handling and processing of large transcript files by breaking them down into manageable chunks. Notable features include:
- Splitting of transcript text files into smaller parts.
- Configuration options for header and footer content per split.
- Command-line interface for easy usage.

## Usage
1. **Installation**: Clone this repository and compile the utilities using Cargo.
2. **Execution**: Run each utility with appropriate command-line arguments as specified in their respective README files.
3. **Integration**: Utilize the utilities individually or in combination to suit specific text processing requirements.

## Dependencies
Each utility may have its own set of dependencies, detailed in their respective README files. Common dependencies include serde for JSON serialization and deserialization, reqwest for HTTP requests, and structopt for command-line argument parsing.

## License
The project is licensed under the MIT License. See the LICENSE file in each utility's directory for details.

For detailed usage instructions and examples, refer to the README files in each utility's directory.
